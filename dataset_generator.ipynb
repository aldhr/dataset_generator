{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" What does this code does?\\nThis notebook generates 'lig', 'inter', and 'prot' files\\nfrom TSV files retrieved from the Binding DB dataset. Those\\nfiles are properly formatted to be used at RINDTI model\\nhttps://rindti.readthedocs.io/en/master/index.html\\n\\nThe files (TSV, TXT, or images) will contain information \\nabout:\\n    Class balance: This code will downsample the dataset to easily-tune \\n    a max radio of 1:3. Minimum samples per class is also easily-tune parameter.\\n    results/active-inactives_info.txt file generated will provide the class balance per target.\\n    results/class_balance.txt file will contain global information of dataset balance.\\n    This code will balance each target active-inactives radio, NOT just whole set.\\n\\n    Molecular descriptors: This code will generate a image of molecular descriptor of \\n    dataset distribution of all dataset after lipinski rules filtering.\\n    Also complete dataset information can be generated from this code as those molecular\\n    descriptors are generated from rdkit in this notebook.\\n    \\n    pbd2fasta: This code also contain codes that are usuful to get fasta sequences from pdbs\\n    and place that information in new cells in dataframe. This code could be reused in \\n    future as its own as it based on: https://github.com/kalininalab/useful_scripts/tree/main/Ilya\\n\\n    pdb-cleaning: This code also contains a cell code that is useful to clean pdbs from other\\n    non-protein molecules, as ligands, water or metals and get only protein molecules.\\n\\n    pdb folder: This code also generated a folder with pdb structures and renames it as pdb id.pdb,\\n    same name that would be used in prot.tsv id.\\n\\n    Active Threshold: This code also create the active-inactive classification based\\n    on a cutoff of 10 mM. Whereas less than 10 mM indicates positive activity.\\n\\n    Filter by EC number: In case to be interest in specific class of enzymatic activity,\\n    it could be filter by EC number. However, this highly depends on pdb files, since\\n    that number is retrieved from the information contained in that pdb.ent file. If non-existent\\n    will not be parse to dataframe.\\n\\n    Formatted dataset: The dataset is properly formatted to be used at RINDTI model\\n    https://rindti.readthedocs.io/en/master/index.html \\n\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" What does this code does?\n",
        "This notebook generates 'lig', 'inter', and 'prot' files\n",
        "from TSV files retrieved from the Binding DB dataset. Those\n",
        "files are properly formatted to be used at RINDTI model\n",
        "https://rindti.readthedocs.io/en/master/index.html\n",
        "\n",
        "The files (TSV, TXT, or images) will contain information \n",
        "about:\n",
        "    Class balance: This code will downsample the dataset to easily-tune \n",
        "    a max radio of 1:3. Minimum samples per class is also easily-tune parameter.\n",
        "    results/active-inactives_info.txt file generated will provide the class balance per target.\n",
        "    results/class_balance.txt file will contain global information of dataset balance.\n",
        "    This code will balance each target active-inactives radio, NOT just whole set.\n",
        "\n",
        "    Molecular descriptors: This code will generate a image of molecular descriptor of \n",
        "    dataset distribution of all dataset after lipinski rules filtering.\n",
        "    Also complete dataset information can be generated from this code as those molecular\n",
        "    descriptors are generated from rdkit in this notebook.\n",
        "    \n",
        "    pbd2fasta: This code also contain codes that are usuful to get fasta sequences from pdbs\n",
        "    and place that information in new cells in dataframe. This code could be reused in \n",
        "    future as its own as it based on: https://github.com/kalininalab/useful_scripts/tree/main/Ilya\n",
        "\n",
        "    pdb-cleaning: This code also contains a cell code that is useful to clean pdbs from other\n",
        "    non-protein molecules, as ligands, water or metals and get only protein molecules.\n",
        "\n",
        "    pdb folder: This code also generated a folder with pdb structures and renames it as pdb id.pdb,\n",
        "    same name that would be used in prot.tsv id.\n",
        "\n",
        "    Active Threshold: This code also create the active-inactive classification based\n",
        "    on a cutoff of 10 mM. Whereas less than 10 mM indicates positive activity.\n",
        "\n",
        "    Filter by EC number: In case to be interest in specific class of enzymatic activity,\n",
        "    it could be filter by EC number. However, this highly depends on pdb files, since\n",
        "    that number is retrieved from the information contained in that pdb.ent file. If non-existent\n",
        "    will not be parse to dataframe.\n",
        "\n",
        "    Formatted dataset: The dataset is properly formatted to be used at RINDTI model\n",
        "    https://rindti.readthedocs.io/en/master/index.html \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8291/3427304583.py:20: DtypeWarning: Columns (9,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dataset = pd.read_csv(str(pwd) + \"/\" + str(db), sep=\"\\t\",\n"
          ]
        }
      ],
      "source": [
        "## general libraries of the notebook\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## define working directory\n",
        "pwd = os.getcwd()\n",
        "\n",
        "## possible datasets manually retrived from:\n",
        "## https://www.bindingdb.org/rwd/bind/chemsearch/marvin/Download.jsp\n",
        "#db = 'BindingDB_ChEMBL.tsv'\n",
        "#db = 'BindingDB_PubChem.tsv'\n",
        "#db = 'BindingDB_BindingDB_Articles.tsv'\n",
        "#db = 'BindingDB_Covid-19.tsv'\n",
        "db = 'BindingDB_All.tsv'\n",
        "\n",
        "# parse binding data into dataset [only columns that really matters]\n",
        "dataset = pd.read_csv(str(pwd) + \"/\" + str(db), sep=\"\\t\",\n",
        "                      usecols=['BindingDB Reactant_set_id', 'Ligand SMILES', 'Target Name', 'IC50 (nM)', 'PDB ID(s) for Ligand-Target Complex'])\n",
        "\n",
        "# create folder for results that would be generated\n",
        "new_folder = './results_' + str(db.replace('.tsv', ''))\n",
        "\n",
        "# check whether directory already exists\n",
        "if not os.path.exists(new_folder):\n",
        "    os.mkdir(new_folder)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" First step |\n",
        "This part of the notebook filters the dataset by only considering targets that have PDB structures. \n",
        "Structural information is cleaned from non-protein molecules and placed into a results/pdbs folder. \n",
        "Additionally, fasta sequences are added to the dataframe.\n",
        "\"\"\"\n",
        "\n",
        "## keep data in dataset only if pdb is available\n",
        "dataset = dataset[dataset['PDB ID(s) for Ligand-Target Complex'].notna()]\n",
        "# # Extract the first pdb ID from each element in the column\n",
        "dataset['PDB ID(s) for Ligand-Target Complex'] = dataset['PDB ID(s) for Ligand-Target Complex'].str.split(',').str.get(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Checkpoint | This cell is designed to only to work with less complexes \n",
        "to just be sure code runs, basically it will avoid to download huge amount of pdb files\n",
        "however, second part balancing probably will requiere more samples to work properly.\"\"\"\n",
        "\n",
        "## turn off following line to work with entire set\n",
        "dataset = dataset.sample(n=30, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading PDB structure '1xkk'...\n",
            "Progress: |█---------------------------------------| 3.33%\n",
            "Downloading PDB structure '4g5j'...\n",
            "Progress: |███-------------------------------------| 6.67%\n",
            "Downloading PDB structure '1vot'...\n",
            "Progress: |████------------------------------------| 10.0%\n",
            "Downloading PDB structure '2ivu'...\n",
            "Progress: |█████-----------------------------------| 13.33%\n",
            "Downloading PDB structure '6h1t'...\n",
            "Progress: |███████---------------------------------| 16.67%\n",
            "Downloading PDB structure '2hi4'...\n",
            "Progress: |████████--------------------------------| 20.0%\n",
            "Downloading PDB structure '5wmd'...\n",
            "Progress: |█████████-------------------------------| 23.33%\n",
            "Downloading PDB structure '5sjr'...\n",
            "Progress: |███████████-----------------------------| 26.67%\n",
            "Downloading PDB structure '4ygf'...\n",
            "Progress: |████████████----------------------------| 30.0%\n",
            "Downloading PDB structure '3b67'...\n",
            "Progress: |█████████████---------------------------| 33.33%\n",
            "Downloading PDB structure '5uer'...\n",
            "Progress: |███████████████-------------------------| 36.67%\n",
            "Downloading PDB structure '5wnk'...\n",
            "Progress: |████████████████------------------------| 40.0%\n",
            "Downloading PDB structure '7wgp'...\n",
            "Progress: |█████████████████-----------------------| 43.33%\n",
            "Downloading PDB structure '7pim'...\n",
            "Progress: |███████████████████---------------------| 46.67%\n",
            "Downloading PDB structure '2yfx'...\n",
            "Progress: |████████████████████--------------------| 50.0%\n",
            "Downloading PDB structure '6dk1'...\n",
            "Progress: |█████████████████████-------------------| 53.33%\n",
            "Downloading PDB structure '6njj'...\n",
            "Progress: |███████████████████████-----------------| 56.67%\n",
            "Downloading PDB structure '1c8k'...\n",
            "Progress: |████████████████████████----------------| 60.0%\n",
            "Downloading PDB structure '2aox'...\n",
            "Progress: |█████████████████████████---------------| 63.33%\n",
            "Downloading PDB structure '1zdp'...\n",
            "Progress: |███████████████████████████-------------| 66.67%\n",
            "Downloading PDB structure '5jax'...\n",
            "Progress: |████████████████████████████------------| 70.0%\n",
            "Downloading PDB structure '5y5n'...\n",
            "Progress: |█████████████████████████████-----------| 73.33%\n",
            "Downloading PDB structure '6x10'...\n",
            "Progress: |███████████████████████████████---------| 76.67%\n",
            "Downloading PDB structure '1aj6'...\n",
            "Progress: |████████████████████████████████--------| 80.0%\n",
            "Downloading PDB structure '7sgg'...\n",
            "Progress: |█████████████████████████████████-------| 83.33%\n",
            "Downloading PDB structure '5bwh'...\n",
            "Progress: |███████████████████████████████████-----| 86.67%\n",
            "Downloading PDB structure '7wfr'...\n",
            "Progress: |████████████████████████████████████----| 90.0%\n",
            "Downloading PDB structure '5wgl'...\n",
            "Progress: |█████████████████████████████████████---| 93.33%\n",
            "Downloading PDB structure '2ito'...\n",
            "Progress: |███████████████████████████████████████-| 96.67%\n",
            "Downloading PDB structure '4ja8'...\n",
            "Progress: |████████████████████████████████████████| 100.0%\n",
            "Downloading PDB structure '1xkk'...\n",
            "Progress: |█---------------------------------------| 3.33%\n",
            "Downloading PDB structure '4g5j'...\n",
            "Progress: |███-------------------------------------| 6.67%\n",
            "Downloading PDB structure '1vot'...\n",
            "Progress: |████------------------------------------| 10.0%\n",
            "Downloading PDB structure '2ivu'...\n",
            "Progress: |█████-----------------------------------| 13.33%\n",
            "Downloading PDB structure '6h1t'...\n",
            "Progress: |███████---------------------------------| 16.67%\n",
            "Downloading PDB structure '2hi4'...\n",
            "Progress: |████████--------------------------------| 20.0%\n",
            "Downloading PDB structure '5wmd'...\n",
            "Progress: |█████████-------------------------------| 23.33%\n",
            "Downloading PDB structure '5sjr'...\n",
            "Progress: |███████████-----------------------------| 26.67%\n",
            "Downloading PDB structure '4ygf'...\n",
            "Progress: |████████████----------------------------| 30.0%\n",
            "Downloading PDB structure '3b67'...\n",
            "Progress: |█████████████---------------------------| 33.33%\n",
            "Downloading PDB structure '5uer'...\n",
            "Progress: |███████████████-------------------------| 36.67%\n",
            "Downloading PDB structure '5wnk'...\n",
            "Progress: |████████████████------------------------| 40.0%\n",
            "Downloading PDB structure '7wgp'...\n",
            "Progress: |█████████████████-----------------------| 43.33%\n",
            "Downloading PDB structure '7pim'...\n",
            "Progress: |███████████████████---------------------| 46.67%\n",
            "Downloading PDB structure '2yfx'...\n",
            "Progress: |████████████████████--------------------| 50.0%\n",
            "Downloading PDB structure '6dk1'...\n",
            "Progress: |█████████████████████-------------------| 53.33%\n",
            "Downloading PDB structure '6njj'...\n",
            "Progress: |███████████████████████-----------------| 56.67%\n",
            "Downloading PDB structure '1c8k'...\n",
            "Progress: |████████████████████████----------------| 60.0%\n",
            "Downloading PDB structure '2aox'...\n",
            "Progress: |█████████████████████████---------------| 63.33%\n",
            "Downloading PDB structure '1zdp'...\n",
            "Progress: |███████████████████████████-------------| 66.67%\n",
            "Downloading PDB structure '5jax'...\n",
            "Progress: |████████████████████████████------------| 70.0%\n",
            "Downloading PDB structure '5y5n'...\n",
            "Progress: |█████████████████████████████-----------| 73.33%\n",
            "Downloading PDB structure '6x10'...\n",
            "Progress: |███████████████████████████████---------| 76.67%\n",
            "Downloading PDB structure '1aj6'...\n",
            "Progress: |████████████████████████████████--------| 80.0%\n",
            "Downloading PDB structure '7sgg'...\n",
            "Progress: |█████████████████████████████████-------| 83.33%\n",
            "Downloading PDB structure '5bwh'...\n",
            "Progress: |███████████████████████████████████-----| 86.67%\n",
            "Downloading PDB structure '7wfr'...\n",
            "Progress: |████████████████████████████████████----| 90.0%\n",
            "Downloading PDB structure '5wgl'...\n",
            "Progress: |█████████████████████████████████████---| 93.33%\n",
            "Downloading PDB structure '2ito'...\n",
            "Progress: |███████████████████████████████████████-| 96.67%\n",
            "Downloading PDB structure '4ja8'...\n",
            "Progress: |████████████████████████████████████████| 100.0%\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Download pdb files | In fact, following code will retrieve \"ent\" files\n",
        "from RCSB. pdb files will be converted later. \n",
        "\n",
        "NOTE: Modules are kept in case of repurposing this code for future as its own\n",
        "\"\"\"\n",
        "\n",
        "## Libraries to download pdb data using biopython\n",
        "import os\n",
        "from Bio.PDB.PDBList import PDBList\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Get the PDB IDs from the DataFrame column\n",
        "pdb_ids = dataset['PDB ID(s) for Ligand-Target Complex'].tolist()\n",
        "\n",
        "# Create a directory for saving PDB files\n",
        "os.makedirs('pdbs', exist_ok=True)\n",
        "\n",
        "# Create an instance of PDBList\n",
        "pdb_list = PDBList()\n",
        "\n",
        "# Calculate the total number of structures\n",
        "total_structures = len(pdb_ids)\n",
        "\n",
        "# Define a helper function to update the progress bar\n",
        "def update_progress(progress):\n",
        "    bar_length = 40\n",
        "    filled_length = int(round(bar_length * progress))\n",
        "    bar = '█' * filled_length + '-' * (bar_length - filled_length)\n",
        "    percent = round(progress * 100, 2)\n",
        "    print(f'Progress: |{bar}| {percent}%')\n",
        "\n",
        "# Download the PDB structures for the given IDs with progress bar\n",
        "for i, pdb_id in enumerate(pdb_ids, start=1):\n",
        "    pdb_list.retrieve_pdb_file(pdb_id, file_format='pdb', pdir=str(new_folder) + '/pdbs')\n",
        "    progress = i / total_structures\n",
        "    update_progress(progress)\n",
        "\n",
        "# Track the IDs of failed downloads\n",
        "failed_ids = []\n",
        "\n",
        "# Download the PDB structures for the given IDs with progress bar\n",
        "for i, pdb_id in enumerate(pdb_ids, start=1):\n",
        "    try:\n",
        "        pdb_list.retrieve_pdb_file(pdb_id, file_format='pdb', pdir='pdbs')\n",
        "    except:\n",
        "        failed_ids.append(pdb_id)\n",
        "    progress = i / total_structures\n",
        "    update_progress(progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Get EC ids | This cell is designed to get EC number from PDB.ent\n",
        "files, this will be useful to filter by specfici enzymatic activity\n",
        "\n",
        "NOTE: Modules are kept in case of repurposing this code for future as its own\n",
        "\"\"\"\n",
        "\n",
        "### libraries for add EC numbers\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def extract_ec_number(file_path):\n",
        "    ec_number = None\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.startswith('COMPND'):\n",
        "                match = re.search(r'EC:\\s*([\\d.-]+)', line)\n",
        "                if match:\n",
        "                    ec_number = match.group(1)\n",
        "                    break\n",
        "    return ec_number\n",
        "\n",
        "# Get the PDB IDs from the DataFrame column\n",
        "pdb_ids = dataset['PDB ID(s) for Ligand-Target Complex'].tolist()\n",
        "\n",
        "# List to store the EC numbers\n",
        "ec_numbers = []\n",
        "\n",
        "# Iterate over the PDB IDs\n",
        "for pdb_id in pdb_ids:\n",
        "    pdb_id_lower = pdb_id.lower()\n",
        "    file_path = f\"{new_folder}/pdbs/pdb{pdb_id_lower}.ent\"\n",
        "    ec_number = extract_ec_number(file_path)\n",
        "    ec_numbers.append(ec_number)\n",
        "\n",
        "# Assign EC numbers to the 'EC' column in the dataset\n",
        "dataset['EC number'] = ec_numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to download PDB IDs:\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Remove fail-downloaded pdbs | This cell is designed to remove pdbs that \n",
        "for somereason could not be retrieved, as the model needs pdb structure. \n",
        "It is recommended to manually check how many information is lost and \n",
        "if other options exist to save the data\"\"\"\n",
        "\n",
        "# Dropping rows based on the list of IDs\n",
        "dataset = dataset[~dataset['PDB ID(s) for Ligand-Target Complex'].isin(failed_ids)]\n",
        "\n",
        "# Print the IDs of the PDB files that were not downloaded\n",
        "print(\"Failed to download PDB IDs:\")\n",
        "for pdb_id in failed_ids:\n",
        "    print(pdb_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/30 [00:00<?, ?file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 12349.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 12361.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 12373.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain F is discontinuous at line 12385.\n",
            "  warnings.warn(\n",
            "Cleaning pdb7pim.ent:   3%|▎         | 1/30 [00:00<00:06,  4.23file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5782.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5863.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 5939.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6049.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6073.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 6091.\n",
            "  warnings.warn(\n",
            "Cleaning pdb6dk1.ent:   3%|▎         | 1/30 [00:00<00:06,  4.23file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 24528.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 24570.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 24652.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 24716.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 24780.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 25526.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 26364.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 27052.\n",
            "  warnings.warn(\n",
            "Cleaning pdb5bwh.ent:  10%|█         | 3/30 [00:00<00:07,  3.76file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 10264.\n",
            "  warnings.warn(\n",
            "Cleaning pdb7wfr.ent:  13%|█▎        | 4/30 [00:00<00:05,  4.54file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5012.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5027.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 5042.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 5049.\n",
            "  warnings.warn(\n",
            "Cleaning pdb2aox.ent:  13%|█▎        | 4/30 [00:00<00:05,  4.54file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2617.\n",
            "  warnings.warn(\n",
            "Cleaning pdb1zdp.ent:  30%|███       | 9/30 [00:01<00:02,  8.86file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7376.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7513.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7562.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 8031.\n",
            "  warnings.warn(\n",
            "Cleaning pdb2ivu.ent:  53%|█████▎    | 16/30 [00:01<00:01, 12.47file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6474.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6589.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6660.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 6967.\n",
            "  warnings.warn(\n",
            "Cleaning pdb5jax.ent:  77%|███████▋  | 23/30 [00:02<00:00, 13.59file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11845.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11899.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 11934.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 11969.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 12019.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 12154.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 12267.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 12420.\n",
            "  warnings.warn(\n",
            "Cleaning pdb6njj.ent:  83%|████████▎ | 25/30 [00:02<00:00, 10.52file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11095.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11138.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 11180.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 11216.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 11252.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 11362.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 11486.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 11612.\n",
            "  warnings.warn(\n",
            "Cleaning pdb2ito.ent:  90%|█████████ | 27/30 [00:02<00:00, 10.33file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 15867.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 15983.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 16110.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 16216.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 16332.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 16610.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 16885.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 17150.\n",
            "  warnings.warn(\n",
            "Cleaning pdb6h1t.ent:  90%|█████████ | 27/30 [00:03<00:00, 10.33file(s)/s]/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 16163.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 16184.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 16199.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 16220.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 16235.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain F is discontinuous at line 16256.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 16271.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain H is discontinuous at line 16292.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 16313.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 16403.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 16537.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 16747.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 16815.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain F is discontinuous at line 17052.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 17121.\n",
            "  warnings.warn(\n",
            "/home/ahr/.local/lib/python3.10/site-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain H is discontinuous at line 17213.\n",
            "  warnings.warn(\n",
            "Cleaning pdb4ygf.ent:  97%|█████████▋| 29/30 [00:03<00:00,  5.67file(s)/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned PDB files saved in ./results_BindingDB_All/pdbs\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Clean pdbs | This cell is designed to clean PDB.ent files\n",
        "from non-protein components and save them in pdb format\n",
        "\n",
        "NOTE: Modules are kept in case of repurposing this code for future as its own\n",
        "\"\"\"\n",
        "\n",
        "## libraries \n",
        "import os\n",
        "from Bio.PDB import PDBParser, PDBIO\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "# Redirect warning output to a null file\n",
        "null_file = open(os.devnull, 'w')\n",
        "sys.stderr = null_file\n",
        "\n",
        "def clean_pdb_files(folder_path):\n",
        "    # Get a list of all .ent files in the folder\n",
        "    ent_files = [f for f in os.listdir(folder_path) if f.endswith('.ent')]\n",
        "\n",
        "    # Initialize the progress bar\n",
        "    progress_bar = tqdm(total=len(ent_files), unit='file(s)')\n",
        "\n",
        "    # Iterate over each .ent file\n",
        "    for ent_file in ent_files:\n",
        "        ent_path = os.path.join(folder_path, ent_file)\n",
        "\n",
        "        # Parse the PDB file\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter('ignore')\n",
        "        parser = PDBParser()\n",
        "        structure = parser.get_structure('pdb', ent_path)\n",
        "\n",
        "        # Remove ligands, metals, and water molecules\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in list(chain):\n",
        "                    hetfield = residue.get_id()[0]\n",
        "                    if hetfield != ' ':\n",
        "                        chain.detach_child(residue.id)\n",
        "\n",
        "        # Save the cleaned PDB file\n",
        "        pdb_id = ent_file.split('.')[0]\n",
        "        pdb_id = pdb_id.replace('pdb', '')\n",
        "        clean_pdb_file = pdb_id + '.pdb'\n",
        "        clean_pdb_path = os.path.join(folder_path, clean_pdb_file)\n",
        "\n",
        "        io = PDBIO()\n",
        "        io.set_structure(structure)\n",
        "        io.save(clean_pdb_path)\n",
        "\n",
        "        # Delete the .ent file\n",
        "        os.remove(ent_path)\n",
        "\n",
        "        progress_bar.set_description(f'Cleaning {ent_file}')\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    progress_bar.close()\n",
        "    print('Cleaned PDB files saved in', folder_path)\n",
        "\n",
        "# Reset the warning output\n",
        "sys.stderr = sys.__stderr__\n",
        "\n",
        "# usage of function\n",
        "folder_path = str(new_folder) + '/pdbs'\n",
        "clean_pdb_files(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Get fasta into dataframe from  pdbs | This cell is designed to place\n",
        "sequence information from pdbs in new cells in dataframe. \n",
        "\n",
        "NOTE: Modules are kept in case of repurposing this code for future as its own\n",
        "\"\"\"\n",
        "\n",
        "### stored in previous steps\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Mapping of three-letter amino acid codes to one-letter codes\n",
        "threetoone = {\n",
        "    \"CYS\": \"C\", \"ASP\": \"D\", \"SER\": \"S\", \"GLN\": \"Q\", \"LYS\": \"K\", \"ILE\": \"I\", \"PRO\": \"P\", \"THR\": \"T\",\n",
        "    \"PHE\": \"F\", \"ASN\": \"N\", \"GLY\": \"G\", \"HIS\": \"H\", \"LEU\": \"L\", \"ARG\": \"R\", \"TRP\": \"W\", \"ALA\": \"A\",\n",
        "    \"VAL\": \"V\", \"GLU\": \"E\", \"TYR\": \"Y\", \"MET\": \"M\",\n",
        "}\n",
        "\n",
        "def pdb_to_sequence(pdb_filename: str, file_extension: str) -> str:\n",
        "    \"\"\"Extract sequence from PDB file and return it as a string.\"\"\"\n",
        "    sequence = \"\"\n",
        "    with open(pdb_filename, \"r\") as file:\n",
        "        for line in file.readlines():\n",
        "            if line.startswith(\"ATOM\") and line[12:16].strip() == \"CA\":\n",
        "                sequence += threetoone[line[17:20].strip()]\n",
        "    return sequence\n",
        "\n",
        "# Update the path to the PDB files\n",
        "pdb_dir = str(new_folder) + \"/pdbs/\"\n",
        "\n",
        "# Iterate over each row in the DataFrame\n",
        "for index, row in dataset.iterrows():\n",
        "    pdb_filename = row['PDB ID(s) for Ligand-Target Complex']\n",
        "    fasta_sequence = \"\"\n",
        "    \n",
        "    if pd.notnull(pdb_filename):\n",
        "        pdb_filename = os.path.join(pdb_dir, pdb_filename.lower() + \".pdb\")  # Convert to lowercase\n",
        "        fasta_sequence = pdb_to_sequence(pdb_filename, \".pdb\")  \n",
        "    \n",
        "    dataset.at[index, \"fasta_sequence\"] = fasta_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Data processing I | Managing columns names and formatting data types\n",
        "\"\"\"\n",
        "\n",
        "# rename columns\n",
        "dataset.columns = ['Drug_ID', 'Drug', 'Target_ID', 'IC50', 'PDB_ID', 'EC number', 'fasta_sequence']\n",
        "# add prefix to drugs\n",
        "dataset['Drug_ID'] = 'drg_' + dataset['Drug_ID'].astype(str)\n",
        "# save ic50 into floats and remove str characters\n",
        "dataset[\"IC50\"] = dataset[\"IC50\"].str.replace('>', '')\n",
        "dataset[\"IC50\"] = dataset[\"IC50\"].str.replace('<', '')\n",
        "# Convert the column to numeric values, setting 'coerce' to convert non-convertible elements to NaN\n",
        "dataset['IC50'] = pd.to_numeric(dataset['IC50'], errors='coerce')\n",
        "# Drop rows with NaN values in the 'IC50' column\n",
        "dataset.dropna(subset=['IC50'], inplace=True)\n",
        "# convert data to float\n",
        "dataset = dataset.astype({\"IC50\": \"float64\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Data processing II | Creating class labels and computing logarithms\n",
        "\"\"\"\n",
        "\n",
        "# create label column in dataset\n",
        "dataset[\"label\"] = np.nan\n",
        "# label as active or inactives ## active < 10mM\n",
        "dataset.loc[dataset['IC50'] < 10000.0, 'label'] = 'active'\n",
        "dataset.loc[dataset['IC50'] >= 10000.0, 'label'] = 'inactive'\n",
        "\n",
        "# compute log of IC50 values\n",
        "# Replace zero values with a small positive value\n",
        "dataset['IC50'] = dataset['IC50'].replace(0, 1e-10)\n",
        "# Convert 'IC50' column to logarithmic values\n",
        "dataset['pIC50'] = np.log10(dataset['IC50'])\n",
        "# Drop duplicates\n",
        "dataset.drop_duplicates(subset=['Drug'], inplace=True)\n",
        "dataset.drop_duplicates(subset=['Drug_ID'], inplace=True)\n",
        "## reset index\n",
        "dataset.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of targets is 17\n",
            " \n",
            "the number of compounds is 17\n",
            " \n",
            "Class blance is \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "active      12\n",
              "inactive     5\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" CHECKPOINT | Initial information of dataset class balance\n",
        "\"\"\"\n",
        "\n",
        "# check for balance\n",
        "print('Num of targets is ' +\n",
        "      str(len(list(dataset['PDB_ID'].drop_duplicates()))))\n",
        "print(' ')\n",
        "print(\"the number of compounds is \" + str(dataset.shape[0]))\n",
        "print(' ')\n",
        "print(\"Class blance is \")\n",
        "dataset['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Drug_ID</th>\n",
              "      <th>Drug</th>\n",
              "      <th>Target_ID</th>\n",
              "      <th>IC50</th>\n",
              "      <th>PDB_ID</th>\n",
              "      <th>EC number</th>\n",
              "      <th>fasta_sequence</th>\n",
              "      <th>label</th>\n",
              "      <th>pIC50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>200643</td>\n",
              "      <td>drg_200648</td>\n",
              "      <td>OC(=O)CNC(=O)C(CS)Cc1ccccc1</td>\n",
              "      <td>EEF1AKMT4-ECE2 readthrough transcript protein</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>1ZDP</td>\n",
              "      <td>3.4.24.27</td>\n",
              "      <td>ITGTSTVGVGRGVLGDQKNINTTYSTYYYLQDNTRGDGIFTYDAKY...</td>\n",
              "      <td>inactive</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index     Drug_ID                         Drug  \\\n",
              "9  200643  drg_200648  OC(=O)CNC(=O)C(CS)Cc1ccccc1   \n",
              "\n",
              "                                       Target_ID      IC50 PDB_ID  EC number  \\\n",
              "9  EEF1AKMT4-ECE2 readthrough transcript protein  100000.0   1ZDP  3.4.24.27   \n",
              "\n",
              "                                      fasta_sequence     label  pIC50  \n",
              "9  ITGTSTVGVGRGVLGDQKNINTTYSTYYYLQDNTRGDGIFTYDAKY...  inactive    5.0  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" FILTER | This cell allows to focus in specific enzymatic activity (EC id)\n",
        "\n",
        "NOTE : This highly depends on pdb files, since that number is retrieved \n",
        "from the information contained in that pdb.ent file. \n",
        "If non-existent will not be parse to dataframe. \n",
        "\"\"\"\n",
        "\n",
        "## for some reason certain pdb ids didn't has EC number on ent files\n",
        "## remove NA from EC number column \n",
        "#dataset = dataset[dataset['EC number'].notna()] \n",
        "\n",
        "\n",
        "## filter by specific enzymatic activity\n",
        "#EC_id = '3.4'\n",
        "#EC_specific_dataset = dataset[dataset['EC number'].str.contains(str(EC_id))]\n",
        "\n",
        "## turn-on this line if you want to apply this filter\n",
        "#dataset = EC_specific_dataset\n",
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Second step |\n",
        "This code will add new columns with molecular descriptors values and will plot\n",
        "the molecular descriptors destribution after dataset filtering by lipinski rules\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Molecular descriptors | This cell uses RDKIT to calculate molecular descriptors,\n",
        "'Molecular formula', 'Molecular Weight', 'Number of Atoms', 'Number of Heavy Atoms', \n",
        "'Hydrogen bond donors', 'Hydrogen bond acceptors', 'Number of rotable bonds', \n",
        "'Polar surface area', 'LogP', 'aromatic rings'\n",
        "\"\"\"\n",
        "\n",
        "#libraries\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import DataStructs\n",
        "from rdkit.Chem import Crippen\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Descriptors import rdMolDescriptors\n",
        "from rdkit.Chem.Draw import MolToImage\n",
        "from rdkit.Chem import MolFromSmiles\n",
        "\n",
        "## create a dataframe columns to place the information computed by RDKIT\n",
        "df = pd.DataFrame(columns=['Molecular formula', 'Molecular Weight', 'Number of Atoms', 'Number of Heavy Atoms', 'Hydrogen bond donors (Lipinski)',\n",
        "                  'Hydrogen bond acceptors (Lipinski)', 'Number of rotable bonds', 'Polar surface area', 'LogP', 'aromatic rings'])\n",
        "\n",
        "# if error skip molecule, It'll be cleaned later\n",
        "def calculate_descriptors(mol):\n",
        "    if mol is None:\n",
        "        return pd.Series({\n",
        "            'formula': None,\n",
        "            'weight': None,\n",
        "            'num_atoms': None,\n",
        "            'num_heavy_atoms': None,\n",
        "            'num_hbd': None,\n",
        "            'num_hba': None,\n",
        "            'num_rot_bonds': None,\n",
        "            'psa': None,\n",
        "            'logp': None,\n",
        "            'num_aromatic_rings': None\n",
        "        })\n",
        "    \n",
        "    mol = Chem.MolFromSmiles(mol)\n",
        "    if mol is None:\n",
        "        return pd.Series({\n",
        "            'formula': None,\n",
        "            'weight': None,\n",
        "            'num_atoms': None,\n",
        "            'num_heavy_atoms': None,\n",
        "            'num_hbd': None,\n",
        "            'num_hba': None,\n",
        "            'num_rot_bonds': None,\n",
        "            'psa': None,\n",
        "            'logp': None,\n",
        "            'num_aromatic_rings': None\n",
        "        })\n",
        "    \n",
        "    formula = rdMolDescriptors.CalcMolFormula(mol)\n",
        "    weight = rdMolDescriptors.CalcExactMolWt(mol)\n",
        "    num_atoms = rdMolDescriptors.CalcNumAtoms(mol)\n",
        "    num_heavy_atoms = rdMolDescriptors.CalcNumHeavyAtoms(mol)\n",
        "    num_hbd = rdMolDescriptors.CalcNumLipinskiHBD(mol)\n",
        "    num_hba = rdMolDescriptors.CalcNumLipinskiHBA(mol)\n",
        "    num_rot_bonds = rdMolDescriptors.CalcNumRotatableBonds(mol)\n",
        "    psa = rdMolDescriptors.CalcTPSA(mol)\n",
        "    logp = Chem.Crippen.MolLogP(mol)\n",
        "    num_aromatic_rings = rdMolDescriptors.CalcNumAromaticRings(mol)\n",
        "    \n",
        "    return pd.Series({\n",
        "        'formula': formula,\n",
        "        'weight': weight,\n",
        "        'num_atoms': num_atoms,\n",
        "        'num_heavy_atoms': num_heavy_atoms,\n",
        "        'num_hbd': num_hbd,\n",
        "        'num_hba': num_hba,\n",
        "        'num_rot_bonds': num_rot_bonds,\n",
        "        'psa': psa,\n",
        "        'logp': logp,\n",
        "        'num_aromatic_rings': num_aromatic_rings\n",
        "    })\n",
        "df = dataset.join(dataset['Drug'].apply(calculate_descriptors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\" Cleaning | This cell removed not-found values in previous step\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mNOTE: output of this cell should be an empty df, since it just shows\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mhowmany NaN exist AFTER cleaning, it could be modified to check\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mhow many drugs you are losting by printing NaN values\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m## remove not found values in previuos step\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# df.dropna(subset=['weight'], inplace=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# df.reset_index(inplace=True)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m## if you want to check which will row will be eliminated\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m## run this three lines before the df.dropna of previous line\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m subset_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mPDB_ID\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m## in case it has NaN values\u001b[39;00m\n\u001b[1;32m     16\u001b[0m subset_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mEC number\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m## in case it has NaN values\u001b[39;00m\n\u001b[1;32m     17\u001b[0m subset_df \u001b[39m=\u001b[39m subset_df[subset_df\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39many(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "\"\"\" Cleaning | This cell removed not-found values in previous step\n",
        "\n",
        "NOTE: output of this cell should be an empty df, since it just shows\n",
        "howmany NaN exist AFTER cleaning, it could be modified by turning-off\n",
        "the first two lines and check how many drugs you are losting by \n",
        "printing NaN values\n",
        "\"\"\"\n",
        "\n",
        "## remove not found values in previuos step\n",
        "df.dropna(subset=['weight'], inplace=True)\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "## check which values still have Nan values \n",
        "## if you want to check which will row will be eliminated\n",
        "## run this three lines before the df.dropna of previous line\n",
        "subset_df = df.drop('PDB_ID', axis=1) ## in case it has NaN values\n",
        "subset_df = df.drop('EC number', axis=1) ## in case it has NaN values\n",
        "subset_df = subset_df[subset_df.isnull().any(axis=1)]\n",
        "subset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Lipinski rules | This cell is used to filter and keep only the drugs \n",
        "that fulfill the statements of the Lipinski rules.\n",
        "\"\"\"\n",
        "# remove all row that contains MW | 500\n",
        "df = df[df.weight < 500]\n",
        "# remove all row that contains logP | 5\n",
        "df = df[df.logp < 5]\n",
        "# remove all row that contains logP | 5\n",
        "df = df[df.logp > 0]\n",
        "# remove all row that contains psa | 140 armgs\n",
        "df = df[df.psa < 140]\n",
        "# remove all row that contains hba | 10\n",
        "df = df[df.num_hba < 10] \n",
        "# remove all row that contains hbd | 5\n",
        "df = df[df.num_hbd < 5] \n",
        "# remove all row that contains rb | 10\n",
        "df = df[df.num_rot_bonds < 10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# Combine the balanced data for all targets into a single DataFrame\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mprint\u001b[39m(balanced_data)\n\u001b[0;32m---> 59\u001b[0m balanced_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(balanced_data)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m         objs,\n\u001b[1;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    422\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ],
      "source": [
        "\"\"\" Balance of the dataset | This code will downsample the dataset to easily-tune \n",
        "a max radio of 1:3. Minimum samples per class is also easily-tune parameter.\n",
        "\n",
        "This code will balance each target active-inactives radio, NOT just\n",
        "whole set\n",
        "\"\"\"\n",
        "\n",
        "## modules \n",
        "from sklearn.utils import resample\n",
        "\n",
        "## target dataframe from original dataframe\n",
        "targets = df['PDB_ID'].unique()\n",
        "\n",
        "## hyperparameters\n",
        "min_examples = 100   # Minimum number of examples for each class\n",
        "max_ratio = 3  # Maximum ratio between the minority and majority classes\n",
        "\n",
        "balanced_data = []\n",
        "\n",
        "## loop for each target\n",
        "for target in targets:\n",
        "    target_data = df[df['PDB_ID'] == target]\n",
        "    \n",
        "    # Calculate the counts of each class\n",
        "    class_counts = target_data['label'].value_counts()\n",
        "    \n",
        "    # only consider targets that has at least 'min_examples' examples in both classes\n",
        "    if len(class_counts) < 2 or any(class_counts < min_examples):\n",
        "        continue\n",
        "    \n",
        "    # determine the minority and majority classes\n",
        "    minority_class = class_counts.idxmin()\n",
        "    majority_class = class_counts.idxmax()\n",
        "    \n",
        "    # Separate the minority and majority classes\n",
        "    minority_data = target_data[target_data['label'] == minority_class]\n",
        "    majority_data = target_data[target_data['label'] == majority_class]\n",
        "    \n",
        "    minority_count = minority_data.shape[0]\n",
        "    majority_count = majority_data.shape[0]\n",
        "    \n",
        "    if minority_count >= min_examples and minority_count * max_ratio <= majority_count:\n",
        "        # Exclude targets with already balanced or minority-dominant class distributions\n",
        "        continue\n",
        "    \n",
        "    if majority_count > minority_count * max_ratio:\n",
        "        # Undersample the majority class to achieve the desired ratio\n",
        "        desired_majority_count = min(minority_count * max_ratio, majority_count)  # Maximum ratio\n",
        "        \n",
        "        undersampled_majority = resample(\n",
        "            majority_data,\n",
        "            replace=False,\n",
        "            n_samples=desired_majority_count,\n",
        "            random_state=42\n",
        "        )\n",
        "        \n",
        "        balanced_target_data = pd.concat([minority_data, undersampled_majority])\n",
        "    else:\n",
        "        balanced_target_data = target_data\n",
        "    \n",
        "    # Add the balanced data for this target to the list\n",
        "    balanced_data.append(balanced_target_data)\n",
        "        \n",
        "# Combine the balanced data for all targets into a single DataFrame\n",
        "balanced_df = pd.concat(balanced_data)\n",
        "\n",
        "# rename dataset to original df\n",
        "df = balanced_df ## basically I reused code already named df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Molecular descriptors plot | This cell uses matplot lib to show and save the \n",
        "chemical distribution image of weight, num of atoms, num of heavy atoms, hb donors, ha acceptors,\n",
        "num of rotable bonds, psa, logP\n",
        "\"\"\"\n",
        "\n",
        "#libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define columns of df to plot\n",
        "columns = [\n",
        "    'weight',\n",
        "    'num_atoms',\n",
        "    'num_heavy_atoms',\n",
        "    'num_hbd',\n",
        "    'num_hba',\n",
        "    'num_rot_bonds',\n",
        "    'psa',\n",
        "    'logp',\n",
        "    'num_aromatic_rings']\n",
        "# Calculate the number of rows and columns\n",
        "n_rows = int(np.ceil(len(columns) / 2))\n",
        "n_cols = 2\n",
        "\n",
        "# Create a figure and subplots with larger size\n",
        "fig, ax = plt.subplots(n_rows, n_cols, figsize=(18, 18))\n",
        "# Make subplots\n",
        "for i, column in enumerate(columns):\n",
        "    axi = ax[i // n_cols][i % n_cols]\n",
        "    fig.suptitle(\"Analysis of mol descriptors\", fontsize=17)\n",
        "    sns.histplot(data=df, x=column, ax=axi, kde=True, color='skyblue')\n",
        "    plt.savefig(str(new_folder) + \"/ChemDistributionof_\" +str(db)+ '.jpg', format='jpg')\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" CHECKPOINT | dataset class balance after filter\n",
        "\"\"\"\n",
        "print('Num of targets is ' +\n",
        "      str(len(list(df['PDB_ID'].drop_duplicates()))))\n",
        "print(' ')\n",
        "print(\"the number of compounds is \" + str(df.shape[0]))\n",
        "print(' ')\n",
        "print(\"Class blance is \")\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Y values distribution | this cell prints and save jpg images of the\n",
        "distribution of pIC50 values of the dataset\n",
        "\"\"\"\n",
        "\n",
        "plt.figure()\n",
        "df['pIC50'].plot(kind='kde')\n",
        "plt.title('pIC50 Distribution of ' + str(db))\n",
        "plt.xlabel('pIC50')\n",
        "plt.ylabel('Density')\n",
        "    \n",
        "# Save the figure\n",
        "plt.savefig(str(new_folder) + \"/pIC50_dist_\" +str(db)+ '.jpg', format='jpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Save active-inactive information | This save a txt files of the\n",
        "class balance information of dataset per target\n",
        "\"\"\"\n",
        "\n",
        "# Get the unique target IDs\n",
        "unique_targets = df['PDB_ID'].unique()\n",
        "\n",
        "# Create a string to store all the information\n",
        "output_string = \"\"\n",
        "\n",
        "# Print the number of unique targets\n",
        "num_targets = len(unique_targets)\n",
        "output_string += 'Num of targets is ' + str(num_targets) + '\\n\\n'\n",
        "\n",
        "# Print the information for each target\n",
        "for target in unique_targets:\n",
        "    output_string += \"PDB_ID ID: \" + str(target) + '\\n'\n",
        "    target_data = df[df['Target_ID'] == target]\n",
        "    \n",
        "    # Print the number of compounds for the current target\n",
        "    num_compounds = target_data.shape[0]\n",
        "    output_string += \"The number of compounds is \" + str(num_compounds) + '\\n'\n",
        "    \n",
        "    # Calculate and print the class balance for the current target\n",
        "    class_balance = target_data['label'].value_counts()\n",
        "    output_string += \"Class balance is:\\n\"\n",
        "    output_string += str(class_balance) + '\\n\\n'\n",
        "\n",
        "# Save the information to a single text file\n",
        "filename = str(new_folder) + \"/active-inactives_info.txt\"\n",
        "with open(filename, 'w') as file:\n",
        "    file.write(output_string)\n",
        "\n",
        "print(\"Output saved to\", filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Save class balance information | This save a txt files of the\n",
        "class balance information of whole dataset \n",
        "\"\"\"\n",
        "\n",
        "# Save the information to a text file\n",
        "filename = str(new_folder) + \"/class_balance.txt\"\n",
        "with open(filename, 'w') as file:\n",
        "    file.write('Num of targets is ' + str(len(list(df['PDB_ID'].drop_duplicates()))) + '\\n\\n')\n",
        "    file.write('The number of compounds is ' + str(df.shape[0]) + '\\n\\n')\n",
        "    file.write('Class balance is:\\n')\n",
        "    file.write(str(df['label'].value_counts()))\n",
        "\n",
        "print(\"Output saved to\", filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Third step |\n",
        "This part generates 'lig', 'inter', and 'prot' files\n",
        "from TSV files retrieved from the Binding DB dataset. Those\n",
        "files are properly formatted to be used at RINDTI model\n",
        "https://rindti.readthedocs.io/en/master/index.html\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Delimit the dataset | creates a new df with only columns that will be useful for the formating\n",
        "\"\"\"\n",
        "# we use df and not dataset, because df is already filtered\n",
        "tsvs = df[['Drug', 'Drug_ID', 'PDB_ID', 'pIC50', 'fasta_sequence']] ## PDB ID will be used to match pdb names\n",
        "# Select and rename columns\n",
        "tsvs = tsvs.rename(columns={'PDB_ID': 'Target_ID', 'pIC50': 'Y', 'fasta_sequence': 'Target'})\n",
        "# Display the updated DataFrame\n",
        "tsvs.to_csv(str(new_folder) + \"/all_drugs.tsv\", sep=\"\\t\", index=False)\n",
        "tsvs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Delimit the dataset | creates a new df with only columns that will be useful for the formating\n",
        "\"\"\"\n",
        "\n",
        "# Read the DataFrame from your data source or use the existing DataFrame\n",
        "df = pd.read_csv(str(new_folder) + '/all_drugs.tsv', sep=\"\\t\")\n",
        "\n",
        "# Remove duplicates and keep the row with the lowest \"Y\" value\n",
        "df = df.sort_values('Y')  # Sort the DataFrame by \"Y\" column in ascending order\n",
        "df = df.drop_duplicates(subset='Drug_ID', keep='first')\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "# Display the updated DataFrame\n",
        "df.to_csv(str(new_folder) + \"/all_drugs.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Delimit the dataset | creates a lig.tsv file\n",
        "\"\"\"\n",
        "lig = df.loc[:, ['Drug_ID', 'Drug']]\n",
        "lig.to_csv(str(new_folder) + \"/lig.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Delimit the dataset | creates a inter.tsv file\n",
        "\"\"\"\n",
        "inter = df.loc[:, ['Drug_ID', 'Target_ID', 'Y']]\n",
        "inter.to_csv(str(new_folder) + \"/inter.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" Delimit the dataset | creates a prot.tsv file\n",
        "\"\"\"\n",
        "prot = df.loc[:, ['Target_ID', 'Target']]\n",
        "prot.to_csv(str(new_folder) + \"/inter.tsv\", sep=\"\\t\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" prot information | creates a TXT file that contains pdb ids \n",
        "\"\"\"\n",
        "# check for how many targets\n",
        "pdb_ids = list(df['Target_ID'].drop_duplicates())\n",
        "len(pdb_ids)\n",
        "# print(pdb_ids)\n",
        "\n",
        "# write their information\n",
        "with open(str(new_folder) + \"/pdb_ids.txt\", \"w\") as output:\n",
        "        output.write(str(pdb_ids))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
